{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c272ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import fhirpathpy\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pathlib\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from phdi.fhir import fhir_server_get\n",
        "from phdi.schemas import load_schema\n",
        "from phdi.azure import AzureFhirServerCredentialManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b87dab",
      "metadata": {},
      "outputs": [],
      "source": [
        "schema_path = Path(\"/path/to/schema.yaml\")\n",
        "base_output_path = Path(\"/path/to/output/directory\")\n",
        "output_format = \"parquet\"\n",
        "fhir_url = \"<FHIR URL>\"\n",
        "cred_manager = AzureFhirServerCredentialManager(fhir_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91b5187b",
      "metadata": {},
      "outputs": [],
      "source": [
        "schema = load_schema(schema_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613ca912",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_data_from_fhir_server(\n",
        "    fhir_url,\n",
        "    table_schema,\n",
        "    cred_manager\n",
        "):\n",
        "    all_data = {}\n",
        "    for resource_type in table_schema:\n",
        "        url = f\"{fhir_url}/{resource_type}?_count=1000\"\n",
        "        data = []\n",
        "        \n",
        "        while url is not None:\n",
        "            access_token = cred_manager.get_access_token().token\n",
        "            response = fhir_server_get(url, access_token)\n",
        "            if response.status_code != 200:\n",
        "                break\n",
        "            \n",
        "            query_result = response.json()\n",
        "            resources = [elem.get(\"resource\") for elem in query_result[\"entry\"]]\n",
        "            resources = list(filter(None, resources))\n",
        "            data.extend(resources)\n",
        "            \n",
        "            for link in query_result.get(\"link\"):\n",
        "                if link.get(\"relation\") == \"next\":\n",
        "                    url = link.get(\"url\", None)\n",
        "                    break\n",
        "                else:\n",
        "                    url = None\n",
        "        \n",
        "        all_data[resource_type] = data\n",
        "        \n",
        "    return all_data\n",
        "\n",
        "def make_table(data, table_schema):\n",
        "    output = {}\n",
        "    for resource_type in data.keys():\n",
        "        for parameters in table_schema[resource_type].values():\n",
        "            parser = fhirpathpy.compile(parameters.get(\"fhir_path\"))\n",
        "            values = [parser(resource)[0] if parser(resource) else None for resource in data[resource_type]]\n",
        "            output[parameters[\"new_name\"]] = values\n",
        "    \n",
        "    return pa.Table.from_pydict(output)\n",
        "\n",
        "def make_table2(data, table_schema):\n",
        "    output = []\n",
        "    for resource_type in data.keys():\n",
        "        parsers = __generate_parsers(table_schema[resource_type].values())\n",
        "        for resource in data[resource_type]:\n",
        "            values = extract_and_filter_resource_values(resource, table_schema[resource_type].values(), parsers)\n",
        "            if values:\n",
        "                output.append(values)\n",
        "    \n",
        "    return pa.Table.from_pylist(output)\n",
        "\n",
        "def __generate_parsers(field_parameters):\n",
        "    parsers = {}\n",
        "    for parameters in field_parameters:\n",
        "        parsers[parameters[\"new_name\"]] = fhirpathpy.compile(parameters[\"fhir_path\"])\n",
        "    return parsers\n",
        "\n",
        "def extract_and_filter_resource_values(resource, field_parameters, parsers):\n",
        "    values = {}\n",
        "    for parameters in field_parameters:\n",
        "        parser = parsers[parameters[\"new_name\"]] \n",
        "        value = parser(resource)\n",
        "        \n",
        "        if len(value) == 0:\n",
        "            values[parameters[\"new_name\"]] = None\n",
        "        elif parameters[\"selection_criteria\"] == \"first\":\n",
        "            values[parameters[\"new_name\"]] = value[0]\n",
        "        elif parameters[\"selection_criteria\"] == \"last\":\n",
        "            values[parameters[\"new_name\"]] = value[-1]\n",
        "        \n",
        "        if isinstance(value, dict):\n",
        "            values[parameters[\"new_name\"]] = json.dumps(value)\n",
        "        elif isinstance(value, list):\n",
        "            values[parameters[\"new_name\"]] = \",\".join(map(str, value))\n",
        "        else:\n",
        "            values[parameters[\"new_name\"]] = value\n",
        "    \n",
        "    return values\n",
        "        \n",
        "def write_table(\n",
        "    data,\n",
        "    output_file_name,\n",
        "    file_format\n",
        "):\n",
        "    writer = pq.ParquetWriter(output_file_name, data.schema)\n",
        "    writer.write_table(table=data)\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd659b5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = {}\n",
        "\n",
        "for table_name in schema.keys():\n",
        "    if (table_name != \"patient\"):\n",
        "        continue\n",
        "    print(f\"\\nCreating the {table_name} table...\")\n",
        "    \n",
        "    output_path = base_output_path / table_name\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "    output_file_name = output_path / f\"{table_name}.{output_format}\"\n",
        "    \n",
        "    start = datetime.now()\n",
        "    data = extract_data_from_fhir_server(fhir_url, schema[table_name], cred_manager)\n",
        "    extract_end = datetime.now()\n",
        "    print(f\"Time to extract {sum(map(len, data.values()))} resources: {extract_end - start}\")\n",
        "    \n",
        "    table = make_table2(data, schema[table_name])\n",
        "    print(f\"Time to tabularize the data: {datetime.now() - extract_end}\")\n",
        "    \n",
        "    all_data[table_name] = table\n",
        "    write_table(table, output_file_name, output_format)\n",
        "    print(f\"Total time spent generating the {table_name} table: {(datetime.now() - start)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc1d30c",
      "metadata": {},
      "outputs": [],
      "source": [
        "for table_name in schema.keys():\n",
        "    output_path = base_output_path / table_name\n",
        "    output_path.mkdir(parents=True, exists_ok=True)\n",
        "    output_file_name = output_path / f\"{table_name}.{output_format}\"\n",
        "    \n",
        "    dtype_map = {\n",
        "        \"string\": pa.string(),\n",
        "        \"timestamp\": pa.timestamp(),\n",
        "        \"float64\": pa.float64()\n",
        "    }\n",
        "    \n",
        "    for resource, fields in schema[table_name].items():\n",
        "        parameters = fields.values()\n",
        "        values = [(param[\"new_name\"], dtype_map[param[\"dtype\"]]) for param in parameters]\n",
        "            \n",
        "    table_schema = pa.schema(values)\n",
        "    \n",
        "    start = datetime.now()\n",
        "    with pa.OSFile(output_file_name, 'wb') as sink:\n",
        "        with pa.ipc.new_file(sink, schema) as writer:\n",
        "            while url is not None:\n",
        "                data, url = \n",
        "                batch = pa.record_batch([pa.array(range(BATCH_SIZE), type=pa.int32())], table_schema)\n",
        "                writer.write(batch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
