{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c272ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import fhirpathpy\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pathlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from phdi_building_blocks.fhir import fhir_server_get\n",
    "from phdi_building_blocks.schemas import load_schema\n",
    "from phdi_building_blocks.azure import AzureFhirServerCredentialManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b87dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path = Path(\"/path/to/schema.yaml\")\n",
    "base_output_path = Path(\"/path/to/output/directory\")\n",
    "output_format = \"parquet\"\n",
    "fhir_url = \"<FHIR URL>\"\n",
    "cred_manager = AzureFhirServerCredentialManager(fhir_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = load_schema(schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ca912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_fhir_server(\n",
    "    fhir_url,\n",
    "    table_schema,\n",
    "    cred_manager\n",
    "):\n",
    "    all_data = {}\n",
    "    for resource_type in table_schema:\n",
    "        url = f\"{fhir_url}/{resource_type}?_count=1000\"\n",
    "        data = []\n",
    "        \n",
    "        while url is not None:\n",
    "            access_token = cred_manager.get_access_token().token\n",
    "            response = fhir_server_get(url, access_token)\n",
    "            if response.status_code != 200:\n",
    "                break\n",
    "            \n",
    "            query_result = response.json()\n",
    "            resources = [elem.get(\"resource\") for elem in query_result[\"entry\"]]\n",
    "            resources = list(filter(None, resources))\n",
    "            data.extend(resources)\n",
    "            \n",
    "            for link in query_result.get(\"link\"):\n",
    "                if link.get(\"relation\") == \"next\":\n",
    "                    url = link.get(\"url\", None)\n",
    "                    break\n",
    "                else:\n",
    "                    url = None\n",
    "        \n",
    "        all_data[resource_type] = data\n",
    "        \n",
    "    return all_data\n",
    "\n",
    "def make_table(data, table_schema):\n",
    "    output = {}\n",
    "    for resource_type in data.keys():\n",
    "        for parameters in table_schema[resource_type].values():\n",
    "            parser = fhirpathpy.compile(parameters.get(\"fhir_path\"))\n",
    "            values = [parser(resource)[0] if parser(resource) else None for resource in data[resource_type]]\n",
    "            output[parameters[\"new_name\"]] = values\n",
    "    \n",
    "    return pa.Table.from_pydict(output)\n",
    "\n",
    "def make_table2(data, table_schema):\n",
    "    output = []\n",
    "    for resource_type in data.keys():\n",
    "        parsers = __generate_parsers(table_schema[resource_type].values())\n",
    "        for resource in data[resource_type]:\n",
    "            values = extract_and_filter_resource_values(resource, table_schema[resource_type].values(), parsers)\n",
    "            if values:\n",
    "                output.append(values)\n",
    "    \n",
    "    return pa.Table.from_pylist(output)\n",
    "\n",
    "def __generate_parsers(field_parameters):\n",
    "    parsers = {}\n",
    "    for parameters in field_parameters:\n",
    "        parsers[parameters[\"new_name\"]] = fhirpathpy.compile(parameters[\"fhir_path\"])\n",
    "    return parsers\n",
    "\n",
    "def extract_and_filter_resource_values(resource, field_parameters, parsers):\n",
    "    values = {}\n",
    "    for parameters in field_parameters:\n",
    "        parser = parsers[parameters[\"new_name\"]] \n",
    "        value = parser(resource)\n",
    "        \n",
    "        if len(value) == 0:\n",
    "            values[parameters[\"new_name\"]] = None\n",
    "        elif parameters[\"selection_criteria\"] == \"first\":\n",
    "            values[parameters[\"new_name\"]] = value[0]\n",
    "        elif parameters[\"selection_criteria\"] == \"last\":\n",
    "            values[parameters[\"new_name\"]] = value[-1]\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            values[parameters[\"new_name\"]] = json.dumps(value)\n",
    "        elif isinstance(value, list):\n",
    "            values[parameters[\"new_name\"]] = \",\".join(map(str, value))\n",
    "        else:\n",
    "            values[parameters[\"new_name\"]] = value\n",
    "    \n",
    "    return values\n",
    "        \n",
    "def write_table(\n",
    "    data,\n",
    "    output_file_name,\n",
    "    file_format\n",
    "):\n",
    "    writer = pq.ParquetWriter(output_file_name, data.schema)\n",
    "    writer.write_table(table=data)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd659b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "for table_name in schema.keys():\n",
    "    if (table_name != \"patient\"):\n",
    "        continue\n",
    "    print(f\"\\nCreating the {table_name} table...\")\n",
    "    \n",
    "    output_path = base_output_path / table_name\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    output_file_name = output_path / f\"{table_name}.{output_format}\"\n",
    "    \n",
    "    start = datetime.now()\n",
    "    data = extract_data_from_fhir_server(fhir_url, schema[table_name], cred_manager)\n",
    "    extract_end = datetime.now()\n",
    "    print(f\"Time to extract {sum(map(len, data.values()))} resources: {extract_end - start}\")\n",
    "    \n",
    "    table = make_table2(data, schema[table_name])\n",
    "    print(f\"Time to tabularize the data: {datetime.now() - extract_end}\")\n",
    "    \n",
    "    all_data[table_name] = table\n",
    "    write_table(table, output_file_name, output_format)\n",
    "    print(f\"Total time spent generating the {table_name} table: {(datetime.now() - start)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in schema.keys():\n",
    "    output_path = base_output_path / table_name\n",
    "    output_path.mkdir(parents=True, exists_ok=True)\n",
    "    output_file_name = output_path / f\"{table_name}.{output_format}\"\n",
    "    \n",
    "    dtype_map = {\n",
    "        \"string\": pa.string(),\n",
    "        \"timestamp\": pa.timestamp(),\n",
    "        \"float64\": pa.float64()\n",
    "    }\n",
    "    \n",
    "    for resource, fields in schema[table_name].items():\n",
    "        parameters = fields.values()\n",
    "        values = [(param[\"new_name\"], dtype_map[param[\"dtype\"]]) for param in parameters]\n",
    "            \n",
    "    table_schema = pa.schema(values)\n",
    "    \n",
    "    start = datetime.now()\n",
    "    with pa.OSFile(output_file_name, 'wb') as sink:\n",
    "        with pa.ipc.new_file(sink, schema) as writer:\n",
    "            while url is not None:\n",
    "                data, url = \n",
    "                batch = pa.record_batch([pa.array(range(BATCH_SIZE), type=pa.int32())], table_schema)\n",
    "                writer.write(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
